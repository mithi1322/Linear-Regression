{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af487110-d2fe-414b-a233-161e311299eb",
   "metadata": {},
   "source": [
    "Q1. What is Lasso Regression, and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ce966b-0b8f-4490-9abc-84d6daec17ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer:\n",
    "'''\n",
    " Lasso Regression, also known as L1 regularization, is a linear regression technique that adds a penalty term to the ordinary least squares (OLS) cost function.\n",
    " It differs from other regression techniques, such as Ridge Regression, in terms of the penalty term used. While Ridge Regression adds the sum of squared coefficients (L2 norm) as the penalty term, \n",
    " Lasso Regression adds the sum of the absolute values of the coefficients (L1 norm). This L1 penalty encourages sparsity in the coefficient estimates, \n",
    " effectively performing feature selection and driving some coefficients to exactly zero.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cac71d9-27d5-4f1d-b6ee-ae6b7942085b",
   "metadata": {},
   "source": [
    "Q2. What is the main advantage of using Lasso Regression in feature selection?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3ef697-502a-4c0a-8b58-1391d7a82534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer:\n",
    "'''\n",
    "The main advantage of using Lasso Regression in feature selection is its ability to automatically select important features by shrinking the coefficients of less relevant variables to zero.\n",
    "By setting coefficients to zero, Lasso Regression provides a sparse model representation, which can be particularly useful when dealing with high-dimensional datasets or when interpretability \n",
    "and simplicity are desired.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166c1c58-a253-42e3-8e4a-35cd8b69d8f3",
   "metadata": {},
   "source": [
    "Q3. How do you interpret the coefficients of a Lasso Regression model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cac84a-6883-4717-996a-2944ea038219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer:\n",
    "'''\n",
    "The interpretation of coefficients in Lasso Regression is similar to other linear regression techniques. The coefficients represent the expected change in the dependent\n",
    "variable associated with a one-unit change in the corresponding independent variable, while holding other variables constant. However, due to the L1 penalty, \n",
    "some coefficients can be exactly zero, indicating that the corresponding feature has been excluded from the model.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3d4773-6951-493f-921a-6f6e8ab84222",
   "metadata": {},
   "source": [
    "Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the\n",
    "model's performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d83942-1d01-4a1f-9c1c-cdf747e5cf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer:\n",
    "'''\n",
    "In Lasso Regression, the main tuning parameter is the regularization parameter (lambda or alpha). The regularization parameter controls the amount of shrinkage applied to the coefficients. \n",
    "Increasing the value of the regularization parameter increases the degree of regularization and leads to more coefficients being pushed to exactly zero. The choice of the regularization parameter \n",
    "depends on the trade-off between model simplicity and predictive performance. Cross-validation techniques can be used to select an optimal value of the regularization parameter based on performancemetrics.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd21d37-f0df-47d8-959b-d8c48d303d49",
   "metadata": {},
   "source": [
    "Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1549eb-6ad4-4f01-b806-4eb7868f3822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer:\n",
    "'''\n",
    "Lasso Regression, in its basic form, is a linear regression technique and is not designed for non-linear regression problems. However, Lasso Regression can be combined with non-linear \n",
    "transformations of the input features to handle non-linear relationships. By introducing non-linear transformations (e.g., polynomial features, interaction terms) into the model, Lasso \n",
    "Regression can capture non-linear patterns in the data.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73969853-0f8a-4e2e-8984-5f8546043183",
   "metadata": {},
   "source": [
    "Q6. What is the difference between Ridge Regression and Lasso Regression?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bf6d4e-7c99-4756-bfff-33ad77bee5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer:\n",
    "'''\n",
    "The main difference between Ridge Regression and Lasso Regression lies in the penalty term used. Ridge Regression adds the sum of squared coefficients (L2 norm) as the penalty term,\n",
    "while Lasso Regression adds the sum of the absolute values of the coefficients (L1 norm). As a result, Ridge Regression can shrink coefficients towards zero but not exactly to zero, \n",
    "whereas Lasso Regression can drive coefficients to exactly zero, effectively performing feature selection.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf1fef3-fb41-4be5-a322-87a2f9e02d18",
   "metadata": {},
   "source": [
    "Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb25771d-92ae-425a-b5ba-14b0ac43371d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer:\n",
    "'''\n",
    "Yes, Lasso Regression can handle multicollinearity in the input features. The L1 penalty in Lasso Regression encourages sparsity and can effectively handle multicollinearity\n",
    "by selecting one variable from a group of highly correlated variables while setting the coefficients of the rest to zero. In this way, Lasso Regression automatically performs \n",
    "variable selection and focuses on the most relevant features.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2a55d3-180d-4ee6-9921-1185fe9f0b97",
   "metadata": {},
   "source": [
    "Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410770de-f507-4482-a036-b4c6d2cdbaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer:\n",
    "'''\n",
    "The optimal value of the regularization parameter (lambda or alpha) in Lasso Regression can be chosen using techniques such as cross-validation. \n",
    "Cross-validation involves splitting the dataset into multiple subsets, fitting the Lasso Regression model with different values of lambda on the training subsets, \n",
    "and evaluating the model's performance on the validation subsets. The value of lambda that provides the best performance, based on a chosen evaluation \n",
    "metric (e.g., mean squared error, cross-validated R-squared), is selected as the optimal value for the regularization parameter.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
